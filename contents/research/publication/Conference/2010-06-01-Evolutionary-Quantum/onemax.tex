The pseudo-Boolean function~\onemax counts the number of one-bits in a bit-string~$\mathbf{x}\in\{0,1\}^n$, that is, let
\begin{equation}
\onemax(\mathbf{x}):=\sum_{i=1}^n \mathbf{x}(i)\,.
\end{equation}

The following theorem can be deduced from the results and proofs in~\cite{DJWoneone}.
\begin{theorem}
Let~$\{\mathbf{x}_t\}_{t\in\NSet}$ be the search points generated by the \ooea or \rls minimizing \onemax. Then the expected query time is in~$\Theta(n\log\,n)$.
\end{theorem}

We show that the expected query time in the quantum version decreases only by a logarithmic factor.
\begin{theorem}
Let~$\{\mathbf{x}_t\}_{t\in\NSet}$ be the search points generated by the \qooea or \qrls minimizing \onemax. Then the expected query time is in $\Theta(n)$.
\end{theorem}

\begin{proof}
Let us first consider \qrls. For all~$t\geq 0$, let~$k_t=\onemax(\mathbf{x}_t)$ be the number of one-bits in~$\mathbf{x}_t$.

Consider~$t\geq 1$. The elements of $\SCal_t$ are precisely those that are obtained from $\mathbf{x}_{t-1}$ by flipping a one-bit. Therefore,~$\SCal_t$ contains exactly $k_{t-1}$ elements, one for every one-bit in~$\mathbf{x}_{t-1}$. Therefore the probability that~$\MutOp{\mathbf{x}_{t-1}}\in\SCal_t$ equals $p_t = k_{t-1}/n$. Furthermore, since exactly one one-bit is flipped, we have~$k_t=k_{t-1}-1$. Recursively, we see~$k_t =k_0-t$, and thus $T=k_0$. Hence,
\[
\EXP[\TQSH\mid k_0] = \sum_{t=1}^{k_0}p_t^{-\nicefrac{1}{2}} =  \sum_{t=1}^{k_0}\sqrt{\frac{n}{k_0-t+1}}  = \sum_{t=1}^{k_0}\frac{\sqrt{n}}{\sqrt{t}}\,.
\]

Therefore, since~$\sum_{t=1}^{k_0}t^{-\nicefrac{1}{2}}\in\Theta\big(\int_1^{k_0}x^{-\nicefrac{1}{2}}dx\big)$, it holds that~$\EXP[\TQSH\mid k_0]\in\Theta(\sqrt{k_0\,n})$.

Since~$\mathbf{x}_0$ is chosen uniformly at random from~$\{0,1\}^n$ it holds that $k_0\geq n/2$~with probability at least $1/2$. Therefore,~$\EXP[\TQSH] = \Omega(n)$. On the other hand, $k_0 \le n$, and so~$\EXP[\TQSH] = \Oh(n)$.

% by the Markov bound \cite{MitzemacherU05} that $k_0\geq n/3$~with a probability bounded away from zero by a positive constant. Hence,~$\EXP[\TQSH] = \Omega(n)$. On the other hand, $k_0 \le n$, and so~$\EXP[\TQSH] = \Oh(n)$.

 
Now, let us turn to \qooea with~$k_t$ as for the \qrls. Let~$t\ge 1$. First note that all vectors in~$\SCal_t$ are obtained from~$\mathbf{x}_{t-1}$ by flipping at least one one-bit. Therefore, by the union bound
\[
p_t\le\frac{ k_{t-1}}{n}\,,
\]
as at least one of the~$k_{t-1}$ one-bits in~$\mathbf{x}_{t-1}$ has to be flipped. Conversely, the set~$\SCal_t$ contains at least all those boolean vectors that are obtained from $\mathbf{x}_{t-1}$ by flipping a one-bit and not flipping any other bit. If we fix a one-bit, then the probability for this event to happen is
\[
\frac{1}{n}\Big(1-\frac{1}{n}\Big)^{n-1} \geq \frac{1}{\euler\,n}
\]
Since we have exactly $k_{t-1}$ one-bits, we obtain the lower bound
\[
p_t\ge\frac{k_{t-1}}{\euler\,n}\,.
\]
Hence,
\[
\sum_{t=1}^{T}\sqrt{\frac{n}{k_{t-1}}}\le\TQSH\le\sum_{t=1}^{T}\sqrt{\frac{\euler\,n}{k_{t-1}}}\,,
\]
that is,~$\EXP[\TQSH]\in\Theta\big(\sqrt{n}\cdot\EXP\big[\sum_{t=1}^{T}k_{t-1}^{-\nicefrac{1}{2}}\big]\big)$.


We may now rewrite the sum~$\sum k_{t-1}^{-\nicefrac{1}{2}}$. For~$\ell\in\{1,\dots,n\}$, let $\delta_\ell := 1$ if there is a $t<T$ such that $ k_t=\ell$, and $\delta_\ell := 0$ otherwise. Then,
\[
\sum_{t=1}^{T}k_{t-1}^{-\nicefrac{1}{2}}=\sum_{\ell=1}^n\delta_\ell\cdot\ell^{-\nicefrac{1}{2}}
\]
Thus, $\EXP[\TQSH]\in\Theta\big(\sqrt{n}\cdot\sum_{\ell=1}^n\,\EXP[\delta_\ell]\,\cdot\ell^{-\nicefrac{1}{2}}\big)$.


Unfortunately, unlike for the~\qrls, we may not assume anymore that~$k_t = k_{t-1}-1$. Thus we prove an upper and a lower bound for $\EXP[\delta_{\ell}]$. The upper bound is trivial, as $\EXP[\delta_{\ell}] \leq 1$. 

Next, we show the corresponding lower bound. Let
\[L:=\{\ell\in\{1,\dots,n\}\colon \delta_\ell = 1\}.\]

We may expect that the values in~$L$ are fairly evenly distributed. Nevertheless, we pessimistically assume that $L=\{n-|L|+1,\dots,n\}$ in order to bound $\sum_{l\geq 1}\delta_\ell\ell^{-\nicefrac{1}{2}}$. Again, $\sum_{\ell=n-|L|+1}^n\ell^{-\nicefrac{1}{2}}\in\Omega\left(\int_{n-|L|+1}^n x^{-\nicefrac{1}{2}}dx\right)$, and thus
\begin{equation}
\label{eq:onemaxc}
\EXP[\TQSH]\in\Omega\left(\sqrt{n}\cdot\EXP\big[\sqrt{n}-\sqrt{n-|L|+1}\,\big]\right)\,.
\end{equation}
To bound the size of~$L$, we consider the expected difference between~$k_{t-1}$ and~$k_t$. Conditioned on the event that at least one of the one-bits in~$\mathbf{x}_{t-1}$ flips, the difference~$k_{t-1}-k_{t}$ is at most the number of further one-bits in~$\mathbf{x}_{t-1}$ that flip. Thus,
\begin{align*}
\EXP[k_{t-1}-k_{t}]&\le 1+\frac{k_{t-1}-1}{n}\le 2\quad\textnormal{and} \\
\EXP[k_0-k_t]&=\sum_{s=1}^{t}\EXP[k_{t-1}-k_t]\le 2t\,.
\end{align*}
Hence, $\EXP[k_0-k_r]\le k_0/2$ for~$r=\lfloor k_0/4\rfloor$. By Markov's In\-equality \cite{MitzemacherU05}, this implies that $k_0-k_r<k_0$, that is,~$k_r>0$\linebreak[4] with probability at least~$1/3$. Thus with probability at least~$1/3$ it holds that~$|L|\ge r+1$, since the values~$k_0,\hdots,k_r$ all differ.

As we have seen in the case of \qrls, also $k_0\ge n/2$ holds with probability at least $1/2$. Thus, with a probability bounded away from zero by a positive constant,~$|L|\ge n/6$. Now we can infer~$\EXP[\TQSH]\in\Omega(n)$ by substituting this result in~(\ref{eq:onemaxc}).
\end{proof}

The pseudo-Boolean function~\discrepancy denotes half the difference in the number of one-bits and zero-bits in a bit-string~$\mathbf{x}\in\{0,1\}^n$ of even length~$n$, that is, let
\begin{equation}
\discrepancy(\mathbf{x}):=\left|\frac{n}{2}-\onemax(\mathbf{x})\right|\,.
\end{equation}


\begin{lemma}\label{lem:discrepancyofX0}
Let~$n\in\NSet$ be even and let~$\mathbf{x}\in\{0,1\}^n$ be chosen uniformly at random. Then,
\[
\EXP[\discrepancy(\mathbf{x})]\in\Theta(n^{\nicefrac{1}{2}})\,.
\]
\end{lemma}

\begin{proof}
Let~$n=2k$. Then, the lemma follows from
\[
\EXP[\discrepancy(\mathbf{x})]=2\,\sum_{i=0}^k(k-i)\tbinom{2k}{i}2^{-2k}=k\,\tbinom{2k}{k}\,2^{-2k}
\]
\ignore{
\begin{align*}
\EXP[\discrepancy(\mathbf{x})]
&=2\,\sum_{i=0}^k(k-i)\tbinom{2k}{i}2^{-2k}\\
&=\sum_{i=0}^k\Big((2k-i)\tbinom{2k}{i}-i\tbinom{2k}{i}\Big)\,2^{-2k}\\
&=\sum_{i=0}^k 2k\Big(\tbinom{2k-1}{i}-\tbinom{2k-1}{i-1}\Big)\,2^{-2k}\\
&=2k\,\tbinom{2k-1}{k}\,2^{-2k}\\
&=k\,\tbinom{2k}{k}\,2^{-2k}
\end{align*}
}
and from~$\binom{2k}{k}\sim 2^{2k}/\sqrt{\pi\,k}$ due to Stirling's formula.
\end{proof}

For the function \discrepancy, we show that the query-complexity of the RSHs and QSHs we consider is asymptotically equal.
\begin{theorem}
%Let~$\{\mathbf{x}_t\}_{t\in\NSet}$ be the search points generated by the (1+1)~QEA or QLS minimizing the pseudo-boolean function \discrepancy with~$\mathbf{x}_0=(0,\dots,0)$. Then the expected query time is in $\Theta(n)$.
%
For each of algorithms (1+1)~EA, RLS, (1+1)~QEA, and QLS, the expected optimization time for minimizing \discrepancy with a random starting point $\mathbf{x}_0$  is in $\Theta(\sqrt{n})$.
\end{theorem}

\begin{proof}
Let~$\{\mathbf{x}_t\}_{t\in\NSet}$ be the search points generated by a run.

Without loss of generality, we always assume that the search point $\mathbf{x}_t$ contains at least as many zeroes as ones, i.e. $\onemax(\mathbf{x}_t) \le n/2$, for the other case follows by a symmetric argument. 
%\piyush{I can see that the subsequent states satisfies the
%  property in the case of RLS. However in the case of (1+1)~EA the
%  mutation that flips all bits, however small this probability may be,
%  does not change the objective functions value but destroys the above
%  property}\johannes{You are right, we should have assumed it for all states, which we can fortunately do. Please destroy this message after reading ;-)}
% 

For RLS and (1+1)~EA we define the drift $D_t$ as
\[ 
D_t =
E[\discrepancy(\mathbf{x}_t)-\discrepancy(\mathbf{x}_{t+1})].\]

We show that for all time steps $t$ the drift satisfies the inequality
\begin{equation}\label{eq:drift}
 1\le D_t\le 2\,,
\end{equation}
i.e., both the search heuristics have a constant
drift. By Theorem~\ref{thm:probamp}, the drifts for the quantum
algorithms equal the drifts for the classical algorithms,
respectively.

The lower bound is trivial since
$\discrepancy(\mathbf{x}_{t+1})<\discrepancy(\mathbf{x}_{t})$. Furthermore,
for the RLS the drift is always $1$ since we flip only one bit in
each step.  So it remains to prove the upper bound for (1+1)~EA.

Let $k_t := n-\onemax(\mathbf{x}_t)$ be the number of zero-bits in $\mathbf{x}_t$. Then by the triangle inequality, the drift is at most $\EXP[k_{t}-k_{t+1}]$. (Actually, it will be strictly smaller because it may happen that $k_{t+1} < n/2$.) The expected difference $\EXP[k_{t}-k_{t+1}]$ is upper bounded by the expected number of zero-bits that flip, and even more so by the expected number of bits that flip at all. Recall that $k_{t+1}$ is obtained from $k_t$ by flipping each bit with probability $1/n$, under the condition that at least one bit flips. Thus we may conclude
\begin{align*}
D_t & \le  \EXP[k_{t}-k_{t+1}] \\
& \le  \EXP[\#\text{ of bit flips from } \mathbf{x}_t\text{ to }\mathbf{x}_{t+1}] \\
& \le  1+\sum_{i}\Prob(i\text{-th bit flips})\\
& = 2\,.\\
\end{align*}

%Since we have assumed that there are at least as many zero-bits as one-bits, the drift
%decreases with $k_t$. In order to see this, let us denote by $P(k)$ the probability that one application of \textsc{mut} comprises exactly $k$ bit flips. The number of bit flips is binomially distributed with expected value $1$, so the $P(k)$ are monotonously decreasing, $P(k) \le P(k+1)$ for all $k\geq 1$.
% \piyush{I dont see this for (1+1)~EA. Can you check
%  this out?} \johannes{I have replaced it by a simpler way. The other statement was true but nasty to write down explicitly. Please destroy this comment after reading...}
%Therefore, with
%
%\begin{align*}
%  \lefteqn{D_{\max}:= E[\discrepancy(0^n) - \discrepancy(\textsc{mut}(0^n))}\\
%    && \phantom{D_{\max}:=\discrepancy(\textsc{mut}(0^n))} \mid \textsc{mut}(0^n)\in \SCal_{0^n}]
%\end{align*} 
%the drift at the zero vector $0^n$, we have
%\[
%D_t  \le  D_{\max} \le  1+ \sum_{i=1}^n \Prob(i\text{-th bit flipped}) = 2
%\]

Adding up $D_s$ for all $0 \le s \le t$, equation \eqref{eq:drift} yields bounds for the total drift from $\mathbf{x}_0$ to $\mathbf{x}_t$, for $t\leq T$:
\[
t \le \EXP[\discrepancy(\mathbf{x}_0)]-\EXP[\discrepancy(\mathbf{x}_t)\mid T \geq t] \le 2t. 
\]

In particular, doing the same process for $t=T$ and computing expected values, we get
\[
\EXP[T] \le \EXP[\discrepancy(\mathbf{x}_0)]-\EXP[\discrepancy(\mathbf{x}_T)]=\EXP[\discrepancy(\mathbf{x}_0)]\le 2 \EXP[T]\, , 
\]
which in turn gives 
\[
\tfrac{1}{2}\EXP[\discrepancy(\mathbf{x}_0)]\le \EXP[T] \le \EXP[\discrepancy(\mathbf{x}_0)].
\]

Now we show that uniformly for all~$\xvec\in\mathcal{S}$, the transition probability~$p_{\xvec}$ is bounded by constants. For all~$\xvec\in\mathcal{S}$, let~$d_{\xvec}:=\discrepancy(\xvec)$.

For RLS, we have ~$p_{\xvec} = 1/n \cdot (n/2 + d_{\xvec}) \geq 1/2$ for all $\xvec$, since the discrepancy decreases whenever a zero-bit is flipped. Hence, $1/2 \le p_{\xvec} \le 1$.

For the (1+1)~EA, the selection rule accepts at least those Boolean strings obtained from $\xvec$ by flipping a single zero-bit and no other bit. Since there are $d_{\xvec} \ge n/2$ zero-bits in $\xvec$, we find a lower bound for $p_{\xvec}$:
\[
p_t \ge k_{t-1}\cdot\frac{1}{n}\cdot\Big(1-\frac{1}{n}\Big)^{n-1}\ge \frac{1}{2e}\,.
\]
In both cases we have proven $\frac{1}{2e} \le p_t \le 1$ for all $0 < t \leq T$. Therefore, by Lemma~\ref{lem:boundedq},
\[
\frac{1}{\sqrt{2e}}\EXP[T]\le \TQSH \le \EXP[T],
\]
and in particular
\[
\EXP[\TQSH] = \Theta(\EXP[T]) = \Theta(\EXP[\discrepancy(\mathbf{x}_0)]).
\]

Finally, by Lemma~\ref{lem:discrepancyofX0} the expected discrepancy of $X_0$ is in $\Theta(n^{\nicefrac{1}{2}})$, so the result follows.
\end{proof}

